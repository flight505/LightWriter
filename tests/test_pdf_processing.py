"""End-to-end tests for PDF processing pipeline."""

import asyncio
import shutil
from pathlib import Path
from typing import Any, Dict
from unittest.mock import MagicMock, patch

import numpy as np
import pytest

from src.core.store.manager import StoreManager
from src.processing.pipeline import ProcessingPipeline
from src.utils.constants import DEFAULT_STORE_PATH, ProcessingState

pytestmark = pytest.mark.asyncio  # Mark all tests as async

# Test data directories
ORIGINAL_PDFS_DIR = Path("tests/pdfs").absolute()
TEST_STORE_PATH = DEFAULT_STORE_PATH / "test_results" / "test_store"
TEST_PDFS_DIR = TEST_STORE_PATH / "test_pdfs"

# Mock data for external APIs
MOCK_IDENTIFIER_INFO = {
    "identifier": "10.1234/test",
    "identifier_type": "doi",
    "title": "Test Paper",
    "authors": [{"full_name": "Test Author"}],
    "method": "extraction",
}

MOCK_CROSSREF_RESPONSE = {
    "message": {
        "title": ["Test Paper"],
        "author": [{"given": "Test", "family": "Author"}],
        "reference": [{"article-title": "Referenced Paper", "author": "Other Author", "year": "2023"}],
    }
}


@pytest.fixture(scope="function")
async def test_pdfs():
    """Create temporary test PDFs directory with copied files."""
    # Ensure original PDFs exist
    assert ORIGINAL_PDFS_DIR.exists(), f"Original PDFs directory not found: {ORIGINAL_PDFS_DIR}"
    original_pdfs = list(ORIGINAL_PDFS_DIR.glob("*.pdf"))
    assert len(original_pdfs) > 0, "No PDFs found in original directory"

    # Create temporary directory
    if TEST_PDFS_DIR.exists():
        shutil.rmtree(TEST_PDFS_DIR)
    TEST_PDFS_DIR.mkdir(parents=True)

    # Copy just one PDF for faster testing
    test_pdf = min(original_pdfs, key=lambda p: p.stat().st_size)  # Use smallest PDF
    shutil.copy2(test_pdf, TEST_PDFS_DIR / test_pdf.name)

    yield TEST_PDFS_DIR

    # Cleanup
    if TEST_PDFS_DIR.exists():
        shutil.rmtree(TEST_PDFS_DIR)


@pytest.fixture(scope="function")
async def store_path():
    """Create and clean test store path."""
    path = TEST_STORE_PATH
    if path.exists():
        shutil.rmtree(path, ignore_errors=True)
    path.mkdir(parents=True)

    # Create required subdirectories
    (path / "lightrag" / "documents").mkdir(parents=True)
    (path / "lightrag" / "vectors").mkdir(parents=True)
    (path / "lightrag" / "metadata").mkdir(parents=True)

    yield path
    if path.exists():
        shutil.rmtree(path, ignore_errors=True)


@pytest.fixture(scope="function")
async def store_manager(store_path):
    """Create test store manager."""

    # Mock embedding function
    def mock_embedding_func(texts):
        return np.random.rand(len(texts) if isinstance(texts, list) else 1, 384)

    mock_embedding_func.embedding_dim = 384

    manager = StoreManager(store_path=store_path, embedding_func=mock_embedding_func)
    # Initialize metadata file
    manager.metadata_consolidator._ensure_metadata_file()
    return manager


@pytest.fixture(scope="function")
async def pipeline(store_manager):
    """Create test pipeline with mocked external APIs."""
    pipeline = ProcessingPipeline(store_manager=store_manager)

    # Mock only external API calls
    pipeline.identifier_extractor.extract_identifier = MagicMock(return_value=MOCK_IDENTIFIER_INFO)

    # Mock CrossRef API
    with patch("requests.get") as mock_get:
        mock_response = MagicMock()
        mock_response.json.return_value = MOCK_CROSSREF_RESPONSE
        mock_get.return_value = mock_response

    return pipeline


def validate_metadata(metadata: Dict[str, Any]) -> bool:
    """Validate metadata structure."""
    # Print metadata for debugging
    print("\nValidating metadata:")
    for key, value in metadata.items():
        print(f"{key}: {value}")

    # Basic structure checks
    required_fields = {
        "file_path",  # Should be present from pipeline
        "file_hash",  # Generated by PDF extractor
        "processing",  # Added by pipeline
        "processing_status",  # Added by pipeline
    }

    # Check required fields exist
    missing_fields = required_fields - set(metadata.keys())
    if missing_fields:
        print(f"\nMissing required fields: {missing_fields}")
        return False

    # Check field types
    if not isinstance(metadata.get("references", []), list):
        print("\nReferences is not a list")
        return False

    if not isinstance(metadata.get("equations", []), list):
        print("\nEquations is not a list")
        return False

    if not metadata.get("file_hash"):
        print("\nFile hash is empty")
        return False

    if not metadata.get("file_path"):
        print("\nFile path is empty")
        return False

    return True


@pytest.mark.timeout(120)  # Allow up to 2 minutes for full pipeline processing
async def test_process_all_pdfs(pipeline, store_manager, test_pdfs):
    """Test processing all PDFs in test directory."""
    pdf_files = list(test_pdfs.glob("*.pdf"))
    assert len(pdf_files) > 0, "No test PDFs found"

    for pdf_path in pdf_files:
        print(f"\nProcessing: {pdf_path}")
        # Process PDF with timeout
        try:
            result = await asyncio.wait_for(
                pipeline.process_document(pdf_path),
                timeout=90,  # Allow 90 seconds per file for full pipeline
            )
        except asyncio.TimeoutError:
            pytest.fail(f"Processing timed out for {pdf_path}")

        # Check processing result
        assert isinstance(result, dict), "Result should be a dictionary"
        assert "state" in result, "Result should have state"
        assert "success" in result, "Result should have success flag"
        assert "errors" in result, "Result should have errors list"
        assert result["success"], f"Processing failed: {result['errors']}"
        assert result["state"] == ProcessingState.COMPLETED.value, f"Expected COMPLETED state, got {result['state']}"

        # Verify metadata was stored
        metadata = await store_manager.get_document_metadata_async(pdf_path)
        assert metadata is not None, "Metadata should be stored"

        # Basic metadata validation
        metadata_dict = metadata.model_dump()
        assert validate_metadata(metadata_dict), "Metadata validation failed"

        # Check required fields
        assert metadata.file_path == str(pdf_path), "File path mismatch"
        assert metadata.file_hash, "File hash missing"
        assert metadata.processing_status == ProcessingState.COMPLETED.value, "Processing status should be COMPLETED"

        # Verify PDF extraction results
        assert metadata.title, "Title should be extracted"
        assert metadata.authors, "Authors should be extracted"
        assert metadata.identifier == MOCK_IDENTIFIER_INFO["identifier"], "Identifier mismatch"
        assert metadata.identifier_type == MOCK_IDENTIFIER_INFO["identifier_type"], "Identifier type mismatch"


@pytest.mark.timeout(10)
async def test_error_handling(pipeline):
    """Test error handling with invalid file."""
    result = await pipeline.process_document(Path("nonexistent.pdf"))
    assert not result["success"], "Should fail for nonexistent file"
    assert result["state"] == ProcessingState.FAILED.value, "State should be FAILED"
    assert len(result["errors"]) > 0, "Should have error messages"


@pytest.mark.timeout(120)  # Allow time for full pipeline
async def test_duplicate_processing(pipeline, store_manager, test_pdfs):
    """Test processing same file twice."""
    pdf_files = list(test_pdfs.glob("*.pdf"))
    assert len(pdf_files) > 0, "No test PDFs found"

    pdf_file = pdf_files[0]

    # First processing
    result1 = await pipeline.process_document(pdf_file)
    if result1["success"]:
        metadata1 = await store_manager.get_document_metadata_async(pdf_file)

        # Second processing
        result2 = await pipeline.process_document(pdf_file)
        metadata2 = await store_manager.get_document_metadata_async(pdf_file)

        # Check results
        assert result1["success"] == result2["success"], "Processing results should match"
        assert metadata1.file_hash == metadata2.file_hash, "File hashes should match"
